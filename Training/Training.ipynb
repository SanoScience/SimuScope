{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training was performed using https://github.com/bmaltais/kohya_ss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform the training, follow the instructions provided at https://github.com/bmaltais/kohya_ss. In kohya_ss_CholectL45 and kohya_ss_CholectG_45, the necessary subfolders such as config, img, log, and model are already included. The img folder has already been generated. This setup is designed to be implemented in the kohya GUI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, it is possible to skip using the kohya_ss GUI and directly upload an already generated command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrained model it avaiable here to downoald: https://huggingface.co/runwayml/stable-diffusion-v1-5/blob/main/v1-5-pruned.safetensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrained_model_name download from https://huggingface.co/runwayml/stable-diffusion-v1-5/tree/main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code for training Lora CholectG45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "accelerate launch --num_cpu_threads_per_process=8 \"/.../kohya_ss/sd-scripts/train_network.py\" --network_train_unet_only --bucket_no_upscale --bucket_reso_steps=64 --cache_latents --cache_latents_to_disk --enable_bucket --min_bucket_reso=256 --max_bucket_reso=2048 --gradient_checkpointing --learning_rate=\"0.0012\" --logging_dir=\"/.../WACV_2025/Training/Train_CholectG45/kohya_ss_CholectG45/log\" --lr_scheduler=\"constant_with_warmup\" --lr_scheduler_num_cycles=\"20\" --max_data_loader_n_workers=\"0\" --max_grad_norm=\"1\" --resolution=\"512,512\" --max_train_steps=\"13920\" --min_snr_gamma=5 --mixed_precision=\"fp16\" --network_alpha=\"1\" --network_dim=128 --network_module=networks.lora --optimizer_type=\"Adafactor\" --output_dir=\"/.../WACV_2025/Training/Train_CholectG45/kohya_ss_CholectG45/model\" --output_name=\"Whole_s87_cholect45\" --pretrained_model_name_or_path=\"/.../Pretrained_model_name/v1-5-pruned.safetensors\" --save_every_n_epochs=\"1\" --save_model_as=safetensors --save_precision=\"fp16\" --text_encoder_lr=0.0012 --train_batch_size=\"5\" --train_data_dir=\"/.../WACV_2025/Training/Train_CholectG45/kohya_ss_CholectG45/img\" --unet_lr=0.0012 --xformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code for training Lora CholectL45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "accelerate launch --num_cpu_threads_per_process=8 \"/.../kohya_ss/sd-scripts/train_network.py\" --network_train_unet_only --bucket_no_upscale --bucket_reso_steps=64 --cache_latents --cache_latents_to_disk --enable_bucket --min_bucket_reso=256 --max_bucket_reso=2048 --gradient_checkpointing --learning_rate=\"0.0012\" --logging_dir=\"/.../WACV_2025/Training/Train_CholectL45/kohya_ss_CholectL45/log\" --lr_scheduler=\"constant_with_warmup\" --lr_scheduler_num_cycles=\"20\" --max_data_loader_n_workers=\"0\" --max_grad_norm=\"1\" --resolution=\"512,512\" --max_train_steps=\"13920\" --min_snr_gamma=5 --mixed_precision=\"fp16\" --network_alpha=\"1\" --network_dim=128 --network_module=networks.lora --optimizer_type=\"Adafactor\" --output_dir=\"/.../WACV_2025/Training/Train_CholectL45/kohya_ss_CholectL45/model\" --output_name=\"Whole_s87_cholect45\" --pretrained_model_name_or_path=\"/.../v1-5-pruned.safetensors\" --save_every_n_epochs=\"1\" --save_model_as=safetensors --save_precision=\"fp16\" --text_encoder_lr=0.0012 --train_batch_size=\"5\" --train_data_dir=\"/.../WACV_2025/Training/Train_CholectL45/kohya_ss_CholectL45/img\" --unet_lr=0.0012 --xformers"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
